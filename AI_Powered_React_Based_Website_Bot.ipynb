{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhlemAmmar/AI-Powered-FAQ-Bot-RAG-based-/blob/main/AI_Powered_React_Based_Website_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crawling the React Based Website"
      ],
      "metadata": {
        "id": "j_FkH9HVhtV4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ANsi0we3SWFK"
      },
      "outputs": [],
      "source": [
        "%pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rP4prqlYU7S"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "import time\n",
        "from PIL import Image\n",
        "import csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81zBK4_T7t57"
      },
      "outputs": [],
      "source": [
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome(options=options)\n",
        "driver.get(\"https://www.example.com\")\n",
        "print(driver.title,\"\\n\")\n",
        "page_html = driver.page_source"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Link crawling"
      ],
      "metadata": {
        "id": "XHgLjdqVh5Fv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z8XGXuyIHJ2"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from collections import deque\n",
        "import time\n",
        "\n",
        "\n",
        "start_url = \"https://www.example.com/\"\n",
        "\n",
        "# ---------- Phase 1: Crawl Links ----------\n",
        "visited_urls = set()\n",
        "queue = deque([start_url])\n",
        "\n",
        "while queue:\n",
        "    url = queue.popleft()\n",
        "    if url in visited_urls or not url.startswith(\"https://www.example.com\"):\n",
        "        continue\n",
        "    visited_urls.add(url)\n",
        "\n",
        "    driver.get(url)\n",
        "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
        "    time.sleep(1)\n",
        "\n",
        "    print(f\"\\nüåç Visiting (links phase): {url}\")\n",
        "\n",
        "    links = [a.get_attribute(\"href\") for a in driver.find_elements(By.TAG_NAME, \"a\")]\n",
        "    links = [l for l in links if l]\n",
        "\n",
        "    print(f\"üîó Found {len(links)} links\")\n",
        "    for link in links:\n",
        "        if link not in visited_urls:\n",
        "            queue.append(link)\n",
        "\n",
        "print(\"\\n‚úÖ Link crawling finished\")\n",
        "print(f\"Total unique URLs found: {len(visited_urls)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVOJomJWVcAx"
      },
      "outputs": [],
      "source": [
        "visited_urls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Buttons Navigation"
      ],
      "metadata": {
        "id": "R3i6Uh2iiBxG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mst8CfpZie2J"
      },
      "outputs": [],
      "source": [
        "from selenium.common.exceptions import StaleElementReferenceException\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDuTSsGAYiZC"
      },
      "outputs": [],
      "source": [
        "def getMUIButtons(driver,button,visited_urls,index):\n",
        "\n",
        "\n",
        "            # After click, find MUI buttons fresh from DOM\n",
        "            all_mui_buttons = driver.find_elements(By.CSS_SELECTOR, \".MuiButtonBase-root.MuiMenuItem-root\")\n",
        "            print(f'  Mui buttons number {len(all_mui_buttons)}')\n",
        "\n",
        "            for j in range(len(all_mui_buttons)):\n",
        "                      print(f'  Refetch MUI buttons iteration {j+1}')\n",
        "                      time.sleep(2)\n",
        "\n",
        "\n",
        "                      time.sleep(2)\n",
        "                      all_mui_buttons = driver.find_elements(By.CSS_SELECTOR, \".MuiButtonBase-root.MuiMenuItem-root\")\n",
        "                      print(f'    Mui buttons number {len(all_mui_buttons)}')\n",
        "                      mui_btn = all_mui_buttons[j]\n",
        "                      text = mui_btn.get_attribute(\"innerText\").strip()\n",
        "                      print(f\"    MUI Button #{j+1}: '{text}'\")\n",
        "\n",
        "                      driver.execute_script(\"arguments[0].scrollIntoView(true);\", mui_btn)\n",
        "                      driver.execute_script(\"arguments[0].click();\", mui_btn)\n",
        "                      time.sleep(2)\n",
        "                      print(      driver.current_url)\n",
        "                      if(driver.current_url not in visited_urls):\n",
        "                        visited_urls.add(driver.current_url)\n",
        "\n",
        "                      driver.back()\n",
        "                      WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
        "                      time.sleep(1)\n",
        "\n",
        "                      try:\n",
        "\n",
        "                          driver.execute_script(\"arguments[0].scrollIntoView(true);\", button)\n",
        "\n",
        "                      except StaleElementReferenceException:\n",
        "                            print(\"‚ö†Ô∏è Button went stale, refetching it...\")\n",
        "                            buttons = driver.find_elements(By.TAG_NAME, \"button\")\n",
        "                            if index < len(buttons):\n",
        "                                button = buttons[index]\n",
        "                                driver.execute_script(\"arguments[0].scrollIntoView(true);\", button)\n",
        "                            else:\n",
        "                                print(\"‚ö†Ô∏è Cannot refetch button after reload.\")\n",
        "                                continue\n",
        "                      label = button.text.strip() or button.get_attribute(\"innerText\")\n",
        "                      print(f\"  üëâ ReClicking button n¬∞{index}: {label}\")\n",
        "                      driver.execute_script(\"arguments[0].click();\", button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AxWuCP3UXThc"
      },
      "outputs": [],
      "source": [
        "for url in list(visited_urls): # Iterate over a list created from the set\n",
        "    try:\n",
        "        driver.get(url)\n",
        "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
        "        time.sleep(1)\n",
        "\n",
        "        # Refetch the button list every time\n",
        "        buttons = driver.find_elements(By.TAG_NAME, \"button\")\n",
        "        print(f\"\\nüåç Visiting (button phase): {url}\")\n",
        "        print(f\"üîò Found {len(buttons)} buttons\")\n",
        "\n",
        "        for index in range(len(buttons)):\n",
        "              button = buttons[index]\n",
        "              label = button.text.strip() or button.get_attribute(\"innerText\")\n",
        "              print(f\"üëâ Clicking button n¬∞{index+1} : {label}\")\n",
        "\n",
        "              driver.execute_script(\"arguments[0].scrollIntoView(true);\", button)\n",
        "              driver.execute_script(\"arguments[0].click();\", button)\n",
        "              time.sleep(2)\n",
        "              print(f'CURRENT URL : {driver.current_url}')\n",
        "              if(driver.current_url not in visited_urls):\n",
        "                visited_urls.add(driver.current_url)\n",
        "              getMUIButtons(driver,button,visited_urls,index)\n",
        "\n",
        "              driver.get(url)\n",
        "              WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
        "              time.sleep(1)\n",
        "              buttons = driver.find_elements(By.TAG_NAME, \"button\")\n",
        "\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error on {url}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMhvudc2eirk"
      },
      "outputs": [],
      "source": [
        "visited_urls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Page content"
      ],
      "metadata": {
        "id": "RDr2tPo5iLSf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwRKRQoP4j1Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "url = \"https://www.example.com/page_1\"  # your page\n",
        "driver = webdriver.Chrome(options=options)\n",
        "driver.get(url)\n",
        "time.sleep(3)  # wait for JS to load\n",
        "\n",
        "# ------------------------\n",
        "# Expand all accordions\n",
        "# ------------------------\n",
        "def expad_all_accordions(driver):\n",
        "    accordions = driver.find_elements(By.CSS_SELECTOR, \".MuiAccordionSummary-root\")\n",
        "    for acc in accordions:\n",
        "        try:\n",
        "            acc.click()\n",
        "            time.sleep(0.3)  # small delay so content loads\n",
        "        except:\n",
        "            continue\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nis1OXxrrPuH"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.example.com/page_1\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "def hash_page(driver):\n",
        "    html = driver.page_source\n",
        "    return hashlib.md5(html.encode('utf-8')).hexdigest()"
      ],
      "metadata": {
        "id": "deVe5uJt54r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50x7DTApqXhV",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from logging import currentframe\n",
        "\n",
        "\n",
        "def get_page_content(url):\n",
        "        driver.get(url)\n",
        "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
        "        time.sleep(1)\n",
        "        page_html = driver.page_source\n",
        "        all_page_content=''\n",
        "        current_content=''\n",
        "        # Refetch the button list every time\n",
        "        buttons = driver.find_elements(By.TAG_NAME, \"button\")\n",
        "        print(f\"\\nüåç Visiting (button phase): {url}\")\n",
        "        print(f\"üîò Found {len(buttons)} buttons\")\n",
        "        for index in range(len(buttons)):\n",
        "                      driver.get(url)\n",
        "                      before = hash_page(driver)\n",
        "                      previous_content=current_content\n",
        "                      WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
        "                      time.sleep(1)\n",
        "                      buttons = driver.find_elements(By.TAG_NAME, \"button\")\n",
        "                      time.sleep(2)\n",
        "                      print(f\"üîò Found {len(buttons)} buttons\")\n",
        "                      button = buttons[index]\n",
        "                      label = button.text.strip() or button.get_attribute(\"innerText\")\n",
        "                      if label:\n",
        "                          print('*'*100)\n",
        "                          print(f\"üëâ Clicking button n¬∞{index+1} : {label}\")\n",
        "\n",
        "                          driver.execute_script(\"arguments[0].scrollIntoView(true);\", button)\n",
        "                          driver.execute_script(\"arguments[0].click();\", button)\n",
        "\n",
        "                          time.sleep(2)\n",
        "                          current_url=driver.current_url\n",
        "                          print(f'CURRENT URL : {driver.current_url}')\n",
        "                          after = hash_page(driver)\n",
        "                          if(current_url!=url):\n",
        "                            continue\n",
        "                          expad_all_accordions(driver)\n",
        "                          soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "                          elements = soup.select(\"p, li\")\n",
        "                          content = [el.get_text() for el in elements]\n",
        "                          current_content=''\n",
        "                          for i, text in enumerate(content, 1):\n",
        "                              current_content+=f\"***. {text}\\n\"\n",
        "                          if before != after:\n",
        "                              print(\"Page content changed.\")\n",
        "                              current_lignes=current_content.splitlines()\n",
        "                              previous_lignes=previous_content.splitlines()\n",
        "                              diff_lines = [line for line in current_lignes if line not in previous_lignes]\n",
        "                              #print(\"\\n\".join(diff_lines))\n",
        "                              all_page_content+=\"\\n\".join(diff_lines)\n",
        "                          else:\n",
        "                              print(\"Page content is the same.\")\n",
        "\n",
        "        return all_page_content\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_page_content(url)"
      ],
      "metadata": {
        "id": "ys6_ZMyXJS0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Website FULL  scraping"
      ],
      "metadata": {
        "id": "QJLthD8siS5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "website_scrapped=[]\n",
        "for url in list(visited_urls):\n",
        "  website_scrapped.append({\"url\":url,\"content\":get_page_content(url)})"
      ],
      "metadata": {
        "id": "UEpceg68YepQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in website_scrapped:\n",
        "  print(item[\"url\"])\n",
        "  print(item[\"content\"][:500])"
      ],
      "metadata": {
        "id": "5yUb6s1cb73S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup RAG PIPELINE"
      ],
      "metadata": {
        "id": "RC4Xw4w_tE0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph"
      ],
      "metadata": {
        "id": "TdPyQQqnpMVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import List, TypedDict"
      ],
      "metadata": {
        "id": "a3VEBDw9nd4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"]=userdata.get('LANGSMITH_API_KEY')"
      ],
      "metadata": {
        "id": "8q7oi2yMtBmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU \"langchain[google-genai]\""
      ],
      "metadata": {
        "id": "q5k2jdEutOV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n"
      ],
      "metadata": {
        "id": "XPhuCOwltQM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "# chat model\n",
        "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
      ],
      "metadata": {
        "id": "C03AyGlXtVKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-huggingface"
      ],
      "metadata": {
        "id": "5j6FfV0I6MNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
      ],
      "metadata": {
        "id": "DF9F5pHn6PPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-core"
      ],
      "metadata": {
        "id": "_VgUaf7JtZgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "#v in Memory vector store\n",
        "vector_store = InMemoryVectorStore(embeddings_model)"
      ],
      "metadata": {
        "id": "ckZABya_tdMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document"
      ],
      "metadata": {
        "id": "3Vwuq11JdOxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    Document(page_content=item[\"content\"], metadata={\"url\": item[\"url\"]})\n",
        "    for item in website_scrapped\n",
        "]"
      ],
      "metadata": {
        "id": "DU0J46Sqb9Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total characters: {len(docs[0].page_content)}\")"
      ],
      "metadata": {
        "id": "ddZTphd9eIa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting documents\n",
        "\"\"\"\n",
        "TextSplitter: Object that splits a list of Documents into smaller chunks. Subclass of DocumentTransformer\n",
        "\"\"\"\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,# chunk size (characters)\n",
        "    chunk_overlap=200 # chunk overlap (characters)\n",
        "    )\n",
        "# recursively split the document using common separators like new lines until each chunk is the appropriate size.\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
      ],
      "metadata": {
        "id": "mOTaiSfaeeVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing documents\n",
        "\n",
        "\"\"\"\n",
        " embed the contents of each document split and insert these embeddings into a vector store\n",
        " \"\"\"\n",
        "_ = vector_store.add_documents(documents=all_splits)"
      ],
      "metadata": {
        "id": "8FKVNyDiejct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompt for question-answering\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")"
      ],
      "metadata": {
        "id": "doHZYvtzSWEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_messages = prompt.invoke(\n",
        "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
        ").to_messages()\n",
        "\n",
        "assert len(example_messages) == 1\n",
        "print(example_messages[0].content)"
      ],
      "metadata": {
        "id": "O9b9BY0LS-3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "To use LangGraph, we need to define three things:\n",
        "\n",
        "The state of our application;\n",
        "The nodes of our application (i.e., application steps);\n",
        "The \"control flow\" of our application (e.g., the ordering of the steps).\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# Define state for application\n",
        "# The state of our application controls what data is input to the application, transferred between steps, and output by the application\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str\n",
        "\n",
        "\n",
        "# Define application steps : NODES\n",
        "\n",
        "def retrieve(state: State):\n",
        "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
        "\n",
        "    return {\"context\": retrieved_docs}\n",
        "\n",
        "\n",
        "def generate(state: State):\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"answer\": response.content}"
      ],
      "metadata": {
        "id": "ttpuMlvYTCXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Control flow\n",
        "## Compile application and test\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "f_O5UEDzTFRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"what is the purpose of the website \"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "id": "609uGDjsTHKx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMYMeFULpKoiRiuugXNZYi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}